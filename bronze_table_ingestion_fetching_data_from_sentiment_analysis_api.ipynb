{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4ec667-b314-420d-98e4-2c6f376cd174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to table youtube2.bronze.raw_api_data successfully\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp, round\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, FloatType\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "query_id = \"6863c3830cc1b17b4d95a265\"\n",
    "token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImF5dXNoaS5iaGFpcmFtQHR1ZGlwLmNvbSIsInVzZXJfaWQiOiI2N2I2ZWI2MmYwODE5NjkxMWY2MmUyMTkiLCJvcmdhbml6YXRpb25faWQiOiI2NmFhNjJlY2QyZmQ5ZjJiM2RhMjc5OGEiLCJleHAiOjE3NTMxNzk3NDV9.H4MT-MJOGkZE4Fyt3838AQgLo_4EPwhHn1NqfQYZrQg\"\n",
    "\n",
    "# Request headers\n",
    "request_headers = {\n",
    "    'accept': 'application/json',\n",
    "    'authorization': f'Bearer {token}',\n",
    "}\n",
    "\n",
    "base_url = f'https://discover-api-dev.tellagence.ai/api/v1/analysis/post/{query_id}'\n",
    "\n",
    "payload = {\n",
    "    'start_date': '2021-08-17T18:30:00.000Z',\n",
    "    'end_date': '2025-06-30T18:29:59.999Z',\n",
    "    'data_source_type': 'YouTube Comments',\n",
    "    'page': 1,\n",
    "    'limit': 2000  # I increased to 2000 for less no. of requests (default is 10)\n",
    "}\n",
    "\n",
    "# Schema definition\n",
    "schema = StructType([\n",
    "    StructField(\"record_type\", StringType(), True),\n",
    "    StructField(\"author\", StringType(), True),\n",
    "    StructField(\"author_channel_url\", StringType(), True),\n",
    "    StructField(\"author_profile_image_url\", StringType(), True),\n",
    "    StructField(\"date\", TimestampType(), True),\n",
    "    StructField(\"like_count\", IntegerType(), True),\n",
    "    StructField(\"reply_count\", FloatType(), True),\n",
    "    StructField(\"text\", StringType(), True),\n",
    "    StructField(\"video_id\", StringType(), True),\n",
    "    StructField(\"cluster_sentiment\", StringType(), True),\n",
    "    StructField(\"cluster_sentiment_reasoning\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"creator\", StringType(), True),\n",
    "    StructField(\"video_title\", StringType(), True),\n",
    "    StructField(\"video_thumbnail_url\", StringType(), True),\n",
    "    StructField(\"channel_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Fetch API data\n",
    "def fetch_all_data():\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    all_data = []\n",
    "    while True:\n",
    "        response = requests.get(base_url, headers=request_headers, params=payload)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"API request failed: {response.status_code}\")\n",
    "        api_data = response.json()\n",
    "        page_data = api_data.get('result', [])\n",
    "        if not page_data:\n",
    "            break\n",
    "        for record in page_data:\n",
    "            if 'date' in record and record['date']:\n",
    "                record['date'] = datetime.strptime(record['date'], '%Y-%m-%dT%H:%M:%S')\n",
    "            all_data.append(record)\n",
    "        if api_data['current_page'] >= api_data['total_pages']:\n",
    "            break\n",
    "        payload['page'] += 1\n",
    "        time.sleep(3)\n",
    "    \n",
    "    if not all_data:\n",
    "        raise Exception(\"No data fetched from API\")\n",
    "    \n",
    "    df = spark.createDataFrame(all_data, schema)\n",
    "    df = df.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    df = df.withColumn(\"reply_count\", round(df[\"reply_count\"], 2))  # Limit to 2 decimal places\n",
    "    return df\n",
    "\n",
    "# Execute ingestion\n",
    "try:\n",
    "    df = fetch_all_data()\n",
    "    \n",
    "    # Save to Delta table\n",
    "    spark.sql(\"CREATE CATALOG IF NOT EXISTS youtube2\")\n",
    "    spark.sql(\"CREATE SCHEMA IF NOT EXISTS youtube2.bronze\")\n",
    "    spark.sql(\"USE CATALOG youtube2\")\n",
    "    spark.sql(\"USE SCHEMA bronze\")\n",
    "\n",
    "    df.write.format(\"delta\").mode(\"append\").saveAsTable(\"youtube2.bronze.raw_api_data\")\n",
    "\n",
    "    print(f\"Data saved to table youtube2.bronze.raw_api_data successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6866021157531587,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_table_ingestion_fetching_data_from_sentiment_analysis_api",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}